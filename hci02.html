<!DOCTYPE html>
<html>
  <head>
    <title>Yuxuan Lei</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta charset="utf-8">
    <meta name="format-detection" content="telephone=no">
    <link rel="stylesheet" type="text/css" href="css/core.css">
    <link rel="stylesheet" type="text/css" href="css/elements.css">
    <!-- <link rel="stylesheet" type="text/css" href="css/custom.css"> -->
    <!-- <link rel="icon" type="image/png" href="favicon.png?version=1"> -->
  </head>
  <body class="preload">
    <div class="container-fluid">
      <header>
        <div class="container">
          <div class="row">
            <div class="col-md-6 col-xs-10">
                <a href="https://architecture.mit.edu/subject/spring-2020-4154-3" class="brand"><div class="author">Yuxuan Lei</a></div>
                <a href="index.html" class="brand"><div class="title">PORTFOLIO</div></a></div>
          </div>
        </div>
      </header>
      <section class="intro">
        <div class="container">
          <ul class="filters">
            <li> <a href="index.html" class ="filter">Back Home</a></li>

          </ul>
        </div>
      </section>
      <section>
        <div class="container">
          <div class="row grid blog">
                <div class="inner">
                  <div class="thumb">  
                    <div class="author">
                      <div class="item col-xs-6 xxx">
                        <p id="big_tit">
                          Design Heritage XR
                        </p>
                        <p>The Design Heritage Platform is a collaborative online gallery and XR tool for collecting, sharing, and curating 3D captures of
                          Heritage places and spatial designs. 
                        </p>
                        <!-- <span class="capright"><button class="link"><a href="https://designheritage.mit.edu/index.php?dbase=dh_rv" class="link">
                          MIT Design Heritage Platform</a> </button></span><br><br>
                        <span class="capright"><button class="link"><a href="https://designheritage.mit.edu/a4/" class="link">WebAR Exhibition</a> </button></span> <br><br>
                        <span class="capright"><button class="link"><a href="https://designheritage.mit.edu/_dh_debug/site_a4kobe/DESIGN_HERITAGE/patcher/demo.php?dbase=dh_rv&proj_id=251&exhibit=on&storyname=Final_light_demos" class="link">WebVR Exhibition</a> </button></span> <br> -->
                      </div>
                      <div class="item col-xs-1 xxx">
                      </div>
                      <div class="item col-xs-5 xxx">
                        <ul class="ulnone">
                          <li class="linone">
                            <span class="capleft">Role</span>
                            <span class="capright">XR Developer</span><br>
                            <span class="capright">Front-End Developer</span><br>
                            <span class="capright">UIUX Designer</span>
                            <br>
                          </li>
                          <hr>
                          <li class="linone">
                            <span class="capleft">Director</span>
                            <span class="capright">Takehiko Nagakura</span>
                          </li>
                          <hr>
                          <li class="linone">
                            <span class="capleft">Team</span>
                            <span class="capright">Wenzhe Peng (Developer Leader)</span>
                          </li>
                          <hr>
                          <!-- <li class="linone">
                            <span class="capleft">Link</span>
                           

                          </li>
                          <hr> -->
        
                        </ul>
                      </div>


                      <div class="author">

                        <div class="item col-xs-12 xxx">
                          <p id="tit">DEMO OVERVIEW</p>
                          <a href="https://designheritage.mit.edu/index.php?dbase=dh_rv"><button id="livebutton"> MIT Design Heritage Platform </button></a><br>
                          <a href="https://designheritage.mit.edu/_dh_debug/site_a4kobe/DESIGN_HERITAGE/patcher/demo.php?dbase=dh_rv&proj_id=153&storyname=2021_tokyo_demo&ar=on&nocache=on&rendersc=4&arsc=2&devspec=md"><button id="livebutton"> Implementation 1: 2021 WebAR Exhibition </button></a><br>
                          <a href="https://designheritage.mit.edu/_dh_debug/site_a4kobe/DESIGN_HERITAGE/patcher/demo.php?dbase=dh_rv&proj_id=251&exhibit=on&storyname=Final_light_demos"><button id="livebutton"> Implementation 2: 2021 WebVR Exhibition </button></a><br>

                          <p id="tit">INTRODUCTION</p>
                          <p class="subtit">01 | Motivation</p>
                          <p>When the result of surveying a cultural heritage site is exhibited in museums, researchers and curators face the challenge of organizing a
                            large number of <code>digital and physical artifacts</code> and selectively composing them to convey cohesive, compelling stories to the public. </p>
                            <p>
                              <img src="images/portfolio/hci11/1.jpg" class="imgitem">
                              <p class="subtit">02 | Solution</p>
                            <p>Thus, The MIT Design Heritage Platform provides a solution that allows users to... </p>
                            <br>
                            <img src="images/portfolio/hci11/2.jpg" class="imgitem">
                            <li>Upload and manage <code>multi-media content</code> including 3D mesh models with textures, images, and videos </li>
                            <li>Create <code>narratives</code> by defining animated camera paths and manipulating adjustable parameters(i.e., texture, position) of each object type</li>
                            <li>Design and exhibit <code>web-based interactive VR/AR experiences</code> with limited VR/AR knowledge.</li><br>
                            <p>The platform is developed and funded by MIT Design Heritage Lab led by <code>Takehiko Nagakura</code>. My work focused on the product 
                              design and software development of interactive VR/AR features. 
                               </p>                 
                               <p>Based on the features, we developed several <code>web-based VR/AR programs</code>, and collected thousands of 
                                <code>user data logs</code> . The users' moving view on the smartphones can be reconstructed from a log for data visualization and analysis of the observers’ behaviors. 
                                From the study and evaluation, we verifies that non-intrusively sampled feedback from an interactive
                                multimedia tool can serve as a useful basis for evaluating the users’ experience. Learning from this
                                interaction leads to opportunities for improving curation and exhibit designs.</p>           
                            <br>
                        </div>
                      </div>

 
                        <div class="item col-xs-12 xxx">
                          <p id="tit">STUDY 1: A MOBILE WEBAR EXHIBITION</p>
                          <p>The MIT Design Heritage WebAR program was developed for the Baker House exhibit through 
                            a collaboration between MIT, the Aalto Foundation in Helsinki, and Gallery A4 in Tokyo.
                            The program was put into practice in <code>Tokyo Setagaya Museum(2021.03) </code> and <code>Kobe Prefectural Museum of Art(2021.07)</code>. The study
                             presents how these artifacts can be curated through an augmented reality (AR) exhibit using visitors’ smartphones, and evaluates usage
                              logs collected as the visitors on the museum floor interact with the web application.</p>
                              <br>
                              
                          <p>Test demo with Mobile: Recommended to use Chrome/Safari and iPhones 11/12 or Android devices with 6GB or more RAM. Please charge your smartphone battery
                            above 30%. Other devices may work but without stability.</p>
                          <a href="https://designheritage.mit.edu/_dh_debug/site_a4kobe/DESIGN_HERITAGE/patcher/demo.php?dbase=dh_rv&proj_id=153&storyname=2021_tokyo_demo&ar=on&nocache=on&rendersc=4&arsc=2&devspec=md"><button id="livebutton"> Live Demo </button></a>
                            <br>
                            <img src="images/portfolio/hci11/5.jpg" class="imgitem">

                          <iframe width="100%" height="600" src="https://www.youtube.com/embed/z_5iOSNHjFs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                          </p>


                        <p class="subtit"> 01 | Upload Multi-Media Resources</p>
                        <p>MIT Design Heritage Platorm allows users to upload and manage <code>multimedia content</code> including <code>3D mesh models with 
                          textures</code> (i.e.,obj, glTF), <code>images</code>(i.e.,jpg, png, gif), and <code>videos</code> to a project archive. </p>
                          <p>For development, several 3D scan models, CAD models, and on-site video recordings produced by the MIT team as well as a few hundred scanned, archival drawings
                             and photos provided by Aalto Foundation were initially uploaded onto the site</p>
                        <img src="images/portfolio/hci11/1.gif" class="imgitem">
                        <p class="notation">Figure 1: Multi-Media Assets library</p>
                        <img src="images/portfolio/hci11/2.gif" class="imgitem">
                        <p class="notation">Figure 2: Textured Models</p>
                        <p class="subtit"> 02 | Construct narratives: scenes</p>
                        <p>Media components are spatially
                          composed to curate various scenes
                          that are switchable. Each component
                          may take parts in different contexts</p>
                        <img src="images/portfolio/hci11/3.gif" class="imgitem">
                        <p class="notation">Figure 3: Scene construction and management on PC</p>
                        <img src="images/portfolio/hci11/3.jpg" class="imgitem">
                        <p class="notation">Figure 4: Scene exhibition on mobile </p>
                        <p class="subtit"> 03 | Interaction design</p>
                          <p>In <code>AR-mode</code>,
                            while the visitor moves around the exhibit with the handheld smartphone, the camera’s location relative to the physical markers embedded in the drawings exhibited on the floor causes synchronous
                            updating of the view of the 3D models. By touching the smartphone screen, the visitor can switch to
                            a <code>non-AR “Finger-based mode”</code>, and rotate, move, or magnify the camera to freely inspect the digital
                            models from any preferred vantage point. The data log can reconstruct the moving view through the
                            virtual camera in both these modes, with the identification of the detected AR markers used for
                            tracking</p>
                        <img src="images/portfolio/hci11/4.jpg" class="imgitem">
                        <p class="notation">Figure 5: AR Mode and Finger Mode</p>
                        <p class="subtit"> 04 | COVID-19 Restrictions and Opportunities</p>
                        <table class="tg">
                          <thead>
                            <tr>
                              <th class="tg-0pky" style="font-weight: bold; background-color: blanchedalmond; width: 50%;">COVID-19 Restrictions</th>
                              <th class="tg-0pky" style="font-weight: bold; background-color: blanchedalmond;width: 50%;">Alternative Product Approaches</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td class="tg-0pky">NO: Shared rental devices (and no cabled devices.)</td>
                              <td class="tg-0pky">Use personal mobile phone: No rental devices required.</td>
                            </tr>
                            <tr>
                              <td class="tg-0pky">NO: Apps requiring pre-loading or downloading from app stores.</td>
                              <td class="tg-0pky">Web app (Three.js + AR.js): No apps needs downloaded from the stores.</td>
                            </tr>
                            <tr>
                              <td class="tg-0pky">NO: Onsite control over installation/visitor assistance</td>
                              <td class="tg-0pky">Database-driven website: Dynamic updating of content for curators/designers</td>
                            </tr>
                            <tr>
                              <td class="tg-0pky">Must allow full remote collaboration for development</td>
                              <td class="tg-0pky">Database-driven website: Dynamic updating of content for curators/designers</td>
                            </tr>
                          </tbody>
                          </table>
                          <br>
                          <p class="subtit"> 05 | Analytics: Data logging and reconstructing</p>
                          <p>The program collected <code>device data</code> and <code>tracking log data</code>(about user behaviors). The usage data of the web application initiated 
                            by the visitors on the museum floor logs the camera pose, tracks AR markers, and the activations of UI switches with a half-second interval. The
                             camera pose (position and target) sampled relative to the binary markers, and logged 
                             every half second sent back to Google Analytics data server.
                            </p>
                          <img src="images/portfolio/hci11/6.jpg" class="imgitem">
                          <p>Data visualization in 3D scene shows the reconstructed and continuous camera pose of users</p>
                          <iframe width="100%" height="700px" src="https://www.youtube.com/embed/OpvktpIk7XM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

                          <p class="subtit"> 06 | Findings</p>
                          <p class="subsubtit"> ① AR Vs. Finger Mode</p>
                          <p>The way the digital model is placed in AR has a measurable impact on the spatial distribution
                            of typical viewing angles from which the visitors observe the model (Fig 3). Not only do the
                            walls, floor and table around the exhibit impose physical restrictions on the visitor’s position,
                            but viewers are only comfortable holding and looking through the smartphones in certain
                            body poses. In contrast, the Finger-based mode gives users more freedom in choosing viewing angles, while curators get less control over the way the model is observed</p>
                          <img src="images/portfolio/hci11/7.jpg" class="imgitem">
                          <p class="notation"> Figure 5: The distributions of the visitors’ camera positions around the exhibit: the distribution for AR-mode (top) and the
                            one for Finger-based mode (bottom) shown in the axon (left), section (middle) and plan views (right). Two virtual models
                            are placed on the physical wall, while one is set on the table.</p>

                            <img src="images/portfolio/hci11/9.jpg" class="imgitem">

                            <p class="subsubtit"> ① Visiting Session</p>
                            <p>Enriching contents by mixing virtual and physical exhibition media (3D models, 3D scans,
                              videos, drawings), preparing multiple, user selectable scenes, and adding different interaction methods (AR mode and Finger-based mode) made the exhibit more engaging to the
                              visitors as they seem to spend an additional amount of time to investigate them. Multiple
                              scenes had a particularly pronounced impact in this exhibit.</p>
                            <img src="images/portfolio/hci11/8.jpg" class="imgitem">
                            <p class="notation">Table 1. Statistics from the data logged (at half second intervals) during the first 20 days of the exhibition in Kobe Prefectural Museum from July 11 to July 31 of 2021. Logged visits of less than 5 seconds (about 5% of the total visitor counts)
                              are included although these outliers indicate visitors just testing the application without actually using it. The comparison
                              among the blue and red cells shows the increase of the total viewing time while the time spent on the first scene stays
                              approximately the same. The comparison among the blue and yellow cells shows the increase of the total viewing time
                              while the time spent on the 3D viewing stays approximately the same. The comparison among the blue and green cells
                              shows the increase of the total viewing time while the time spent on viewing in AR mode stays approximately the same.</p>
                              <li> <code>Video clips:</code> 65% of the visitors watched videos (at least one of the 8 clips averaging 37 seconds long ranging from 9 to 97 seconds). Compared with people who did not watch any video, the total duration spent on the web app increased by about 40%, from 100 seconds to 142.
                                People watching videos also looked at the 3D models longer (6 %) possibly encouraged by watching the video.
                                </li>
                                <li> <code>Switch Scenes: </code>The visitors stayed on the first scene for about 73 seconds, and about 50% of them tried the second and third scenes spending additional times. 
                                  The visitors spent less time on each of the second and third scenes than the first scene. This may indicate less successful designs of the second and third scenes, or the constraint by the duration in which each visitor felt comfortable monopolizing the exhibit when others lined up waiting for their turns.
                                  </li>
                                  <li><code>AR Vs. Finger Mode:</code> Majority (77%) of people tried Finger-based viewing. People who did not use Finger mode stayed on AR mode for about 90 seconds, while Finger mode users stayed on this web app for about 60% longer.
                                    This increase of the total viewing time is mostly to examine the model in Finger mode in addition to observing the model in AR. (The time spent on AR mode was not much different in these two groups.) 
                                    </li>
                            
                          <p class="subtit">07 | Future Studies</p>
                            <p>The log data collectable by this web app is a valuable resource for future studies to apply <code>Machine Learning</code>  process. 
                              For instance:
                              <li>Possibility to identify preference of people using the device, and optimize the design of the app and the curation of the scene composition such as media content arrangement and marker placement.</li> 
                              <li>Possibility to identify what architectural features attracts people and use the analysis for synthetic visualization such as automated generation of a movie touring audience around a heritage site and buildings.</li> 
                              </p>
                                                      



                      </div>

 
              <div class="item col-xs-12 ">
                <p id="tit">STUDY 2: A WEBVR EXHIBITION</p>
                <p>A WebVR exhibition was developed with the platform for convenience of PC users, demonstrating the capabilities of the tool in both VR and AR experiences.</p>
                <p><code>Test with PC:</code>Best viewed with a PC or laptop with 8GB or more RAM.</p>
                <a href="https://designheritage.mit.edu/_dh_debug/site_a4kobe/DESIGN_HERITAGE/patcher/demo.php?dbase=dh_rv&proj_id=251&exhibit=on&storyname=Final_light_demos"><button id="livebutton"> Live Demo </button></a>
<br>
                   <img src="images/portfolio/hci11/dh3.gif" class="imgitem">
                  
              </div> 





<!-- 
                      <div class="author">
                        <a class="item col-xs-12 xxx"  href="https://designheritage.mit.edu/index.php?dbase=dh_rv" >
                          <button id="livebutton">Live preview</button></a>
                      </div>

                      <div class="author">
                        <a class="item col-xs-12 xxx">
                       <img width=100% src="images/portfolio/hci11/dh.gif" alt="">
                       <br><br>
                       <img width=100% src="images/portfolio/hci11/dh2.gif" alt="">

                        </a>
                      </div> -->





                  </div>
                </div>
          </div>
        </div>



      </section>

    


      <footer>
        <!-- <div class="container">
          <div class="row">
            <div class="col-md-12 text-center"><span>&copy; Jane Template. All rights reserved.</div>
          </div>
        </div> -->
      </footer>
    </div>
    <script src="js/assets/jquery.js"></script>
    <script src="js/assets/imagesloaded.pkgd.min.js"></script>
    <script src="js/assets/packery.pkgd.min.js"></script>
    <script src="js/functions.js"></script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6YPE9DQ241"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6YPE9DQ241');
</script>
  </body>
</html>
